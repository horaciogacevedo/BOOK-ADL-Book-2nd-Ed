# general libraries
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
from random import *

# tensorflow libraries
import tensorflow.keras as keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Conv2DTranspose
from tensorflow.keras.constraints import max_norm
from tensorflow.keras import backend as K
from keras.utils.vis_utils import plot_model

# Load MNIST dataset
(input_train, target_train), (input_test, target_test) = mnist.load_data()

# Reshape data based on channels first / channels last strategy.
# This is dependent on whether you use TF, Theano or CNTK as backend.
# Source: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py

img_width, img_height = 28, 28

if K.image_data_format() == 'channels_first':
    input_train = input_train.reshape(input_train.shape[0], 1, img_width, img_height)
    input_test = input_test.reshape(input_test.shape[0], 1, img_width, img_height)
    input_shape = (1, img_width, img_height)
else:
    input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 1)
    input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 1)
    input_shape = (img_width, img_height, 1)

# Parse numbers as floats
input_train = input_train.astype('float32')
input_test = input_test.astype('float32')

# Normalize data
input_train = input_train / 255
input_test = input_test / 255

def get_random_element_with_label (data, lbls, lbl):
  """Returns one numpy array (one column) with an example of a choosen label."""
  
  tmp = lbls == lbl
  subset = data[tmp.flatten(), :]
  return subset[randint(0, subset.shape[0]), :]

# The following line is needed to reshape the training dataset 
# (to plot some image examples)
input_example = input_train.reshape(60000, 784)

# The following code create a numpy array where in column 0 you will find 
# an example of label 0, in column 1 of label 1 and so on.
labels_overview = np.empty([784, 10])
for i in range (0, 10):
    col = get_random_element_with_label(input_example, target_train, i)
    labels_overview[:,i] = col

f = plt.figure(figsize = (15, 15))
count = 1
for i in range(0, 10):
  plt.gray()
  plt.subplot(5, 2, count)
  count = count + 1
  plt.subplots_adjust(hspace = 0.5)
  plt.title('Digit: ' + str(i))
  some_digit_image = labels_overview[:, i]
  plt.imshow(some_digit_image.reshape(28, 28))
  plt.axis('off')
  pass

noise_factor = 0.55
pure = input_train
pure_test = input_test
noise = np.random.normal(0, 1, pure.shape)
noise_test = np.random.normal(0, 1, pure_test.shape)
noisy_input = pure + noise_factor * noise
noisy_input_test = pure_test + noise_factor * noise_test

# The following line is needed to reshape the training dataset 
# (to plot some image examples)
input_example_noise = noisy_input.reshape(60000, 784)

# The following code create a numpy array where in column 0 you will find 
# an example of label 0, in column 1 of label 1 and so on.
labels_overview = np.empty([784, 10])
for i in range (0, 10):
    col = get_random_element_with_label(input_example_noise, target_train, i)
    labels_overview[:,i] = col

f = plt.figure(figsize = (15, 15))
count = 1
for i in range(0, 10):
  plt.gray()
  plt.subplot(5, 2, count)
  count = count + 1
  plt.subplots_adjust(hspace = 0.5)
  plt.title('Digit: ' + str(i))
  some_digit_image = labels_overview[:, i]
  plt.imshow(some_digit_image.reshape(28, 28))
  plt.axis('off')
  pass

def create_autoencoders(max_norm_value = 2.0):
  # Create the model
  model = Sequential()
  model.add(Conv2D(64, kernel_size = (3, 3), kernel_constraint = max_norm(max_norm_value), activation = 'relu', kernel_initializer = 'he_uniform', input_shape = input_shape))
  model.add(Conv2D(32, kernel_size = (3, 3), kernel_constraint = max_norm(max_norm_value), activation = 'relu', kernel_initializer = 'he_uniform'))
  model.add(Conv2DTranspose(32, kernel_size = (3,3), kernel_constraint = max_norm(max_norm_value), activation = 'relu', kernel_initializer = 'he_uniform'))
  model.add(Conv2DTranspose(64, kernel_size = (3,3), kernel_constraint = max_norm(max_norm_value), activation = 'relu', kernel_initializer = 'he_uniform'))
  model.add(Conv2D(1, kernel_size = (3, 3), kernel_constraint = max_norm(max_norm_value), activation = 'sigmoid', padding = 'same'))
  return model

model = create_autoencoders()

plot_model(model, show_shapes = True)

# Model configuration
batch_size = 150
no_epochs = 30
validation_split = 0.2

# Compile and fit data
model.compile(optimizer = 'adam', loss = 'binary_crossentropy')
model.fit(noisy_input, pure,
          epochs = no_epochs,
          batch_size = batch_size,
          validation_split = validation_split)

# Generate denoised images
number_of_visualizations = 6
samples = noisy_input_test[:number_of_visualizations]
targets = target_test[:number_of_visualizations]
denoised_images = model.predict(samples)

# Plot denoised images
for i in range(0, number_of_visualizations):
  plt.gray()
  # Get the sample and the reconstruction
  noisy_image = noisy_input_test[i][:, :, 0]
  pure_image  = pure_test[i][:, :, 0]
  denoised_image = denoised_images[i][:, :, 0]
  input_class = targets[i]
  # Matplotlib preparations
  fig, axes = plt.subplots(1, 3)
  fig.set_size_inches(12, 7)
  # Plot sample and reconstruction
  axes[0].imshow(noisy_image)
  axes[0].set_title('Noisy image', fontsize = 16)
  axes[0].get_xaxis().set_visible(False)
  axes[0].get_yaxis().set_visible(False)
  axes[1].imshow(pure_image)
  axes[1].set_title('Pure image', fontsize = 16)
  axes[1].get_xaxis().set_visible(False)
  axes[1].get_yaxis().set_visible(False)
  axes[2].imshow(denoised_image)
  axes[2].set_title('Denoised image', fontsize = 16)
  axes[2].get_xaxis().set_visible(False)
  axes[2].get_yaxis().set_visible(False)
  fig.suptitle(f'MNIST target = {input_class}')
  plt.show()


